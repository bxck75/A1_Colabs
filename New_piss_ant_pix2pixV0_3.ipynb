{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New_piss_ant_pix2pixV0.1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bxck75/A1_Colabs/blob/master/New_piss_ant_pix2pixV0_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TELmRbBrfqFV",
        "colab_type": "text"
      },
      "source": [
        "##Get images and make the dataset\n",
        "    --resize\n",
        "    --blank center clone\n",
        "    --edged clone\n",
        "    --combine blank set\n",
        "    --combine edged set\n",
        "    --split both sets\n",
        "    --copy the combined set to there home "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRqbekgSPIVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# Helpers Loading\n",
        "from pathlib import Path\n",
        "lib_file=Path('/content/lib/Helpers.py')\n",
        "if not lib_file.is_file():\n",
        "    import os\n",
        "    os.system('mkdir -p /content/lib')\n",
        "    os.chdir('/content/lib')\n",
        "    os.system('wget https://raw.githubusercontent.com/bxck75/A1_Colabs/master/Helpers.py')\n",
        "    os.system('wget https://raw.githubusercontent.com/bxck75/A1_Colabs/master/myrepcol.py')\n",
        "    os.chdir('/content/')\n",
        "\n",
        "# #resource monitor\n",
        "# resmon_file = Path('/content/lib/resource_monitor.py')\n",
        "# if not  resmon_file.is_file():\n",
        "#     os.system('wget https://github.com/googlecolab/colabtools/blob/master/google/colab/_serverextension/_resource_monitor.py -O /content/lib/resource_monitor.py')\n",
        "\n",
        "# # import lib.resource_monitor\n",
        "    \n",
        "# patch for imshow\n",
        "patch_file = Path('/content/lib/colab_patches.py')\n",
        "if not patch_file.is_file():\n",
        "    os.system('wget https://raw.githubusercontent.com/googlecolab/colabtools/master/google/colab/patches/__init__.py -O /content/lib/colab_patches.py')\n",
        "\n",
        "import lib.colab_patches\n",
        "from lib.Helpers import Helpers\n",
        "from lib.myrepcol import reps\n",
        "\n",
        "# regular imports\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import HBox, VBox\n",
        "from fastai.vision import *\n",
        "from fastai.vision.gan import *\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import fastai, hashlib, inspect\n",
        "from IPython.display import clear_output\n",
        "from IPython import display\n",
        "\n",
        "# Init helpers\n",
        "H=Helpers()\n",
        "\n",
        "# delete standaard data\n",
        "H.Me(['cml','rm -r /content/sample_data'])\n",
        "\n",
        "# login google session\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# define functions\n",
        "def get_gdrive_dataset(pack, DS_root='datasets',GD_root='datasets'):\n",
        "    import google\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    H.GD_ROOT=GD_root+'/'\n",
        "    H.DS_ROOT=DS_root+'/'\n",
        "    os.chdir(H.gdrive_root+H.GD_ROOT)\n",
        "    H.Me(['mkd',[DS_root,'models'],H.pix_root])\n",
        "    H.Me(['cml','cp -r '+pack+' '+H.pix_root+DS_root])\n",
        "    os.chdir(H.pix_root+DS_root)\n",
        "    H.Me(['cml','unzip -q '+pack])\n",
        "    H.Me(['cml','rm -r '+pack])\n",
        "    os.chdir(H.pix_root)\n",
        "\n",
        "def MethHelp(libs):\n",
        "    os_help=H.Me(['vdir',libs])\n",
        "    #make a list containing libs values of os_help\n",
        "    listOfLibs = [x[0] for x in os_help]\n",
        "    #make a list containing libs method values of os_help\n",
        "    listOfMethods= [x[1] for x in os_help]\n",
        "    # Create a zipped list of tuples from above lists\n",
        "    zippedList =  list(zip(listOfLibs, listOfMethods))\n",
        "    zippedList\n",
        "    # request help on method from list\n",
        "    return zippedList\n",
        "\n",
        "def loadTboard():\n",
        "    import datetime, os\n",
        "    try:\n",
        "        %load_ext tensorboard\n",
        "    except:\n",
        "        %reload_ext tensorboard\n",
        "\n",
        "def html(content):\n",
        "    \"\"\"Publishes given html content into the output.\"\"\"\n",
        "    display.display(display.HTML(content))\n",
        "\n",
        "\n",
        "def css(content=None, url=None):\n",
        "    \"\"\"Publishes css content.\"\"\"\n",
        "    if url is not None:\n",
        "        html('<link rel=stylesheet type=text/css href=%r></link>' % url)\n",
        "    else:\n",
        "        html('<style>' + content + '</style>')\n",
        "\n",
        "\n",
        "def javascript(content=None, url=None, script_id=None):\n",
        "    \"\"\"Publishes javascript content into the output.\"\"\"\n",
        "    if (content is None) == (url is None):\n",
        "        raise ValueError('exactly one of content and url should be none')\n",
        "    if url is not None:\n",
        "        # Note: display.javascript will try to download script from python\n",
        "        # which is very rarely useful.\n",
        "        html('<script src=%r></script>' % url)\n",
        "        return\n",
        "    if not script_id and 'sourceURL=' not in content:\n",
        "        script_id = 'js_' + hashlib.md5(content.encode('utf8')).hexdigest()[:10]\n",
        "\n",
        "    if script_id:\n",
        "        content += '\\n//# sourceURL=%s' % script_id\n",
        "    display.display(display.Javascript(content))\n",
        "\n",
        "# set repository to pull\n",
        "H.reps_custom=['bxck75/piss-ant-pix2pix']# ,'affinelayer/pix2pix-tensorflow','phillipi/pix2pix','shelhamer/clockwork-fcn'\n",
        "H.reps_all=reps # aprox 80 in lib reps\n",
        "\n",
        "H.Me(['inst_reps',H.reps_custom,'/content/installed_reps',True,True])\n",
        "\n",
        "H.pix_root='/content/installed_reps/piss-ant-pix2pix/'\n",
        "H.gdrive_root='/content/drive/My Drive/'\n",
        "H.local_datasets_path=H.pix_root+'datasets/'\n",
        "H.gdrive_datasets_path=H.gdrive_root+'datasets/'\n",
        "H.local_raw_imgs_path=H.pix_root+'raw_img_data/'\n",
        "H.gdrive_raw_imgs_path=H.gdrive_root+'raw_image_packs/'\n",
        "H.gdrive_models_path=H.gdrive_root+'models/'\n",
        "\n",
        "# resource lists\n",
        "H.raw_image_packs=H.Me(['cml','ls \"'    + H.gdrive_raw_imgs_path+'\"'])\n",
        "H.processed_datasets=H.Me(['cml','ls \"' + H.gdrive_datasets_path+'\"'])\n",
        "H.trained_models=H.Me(['cml','ls \"'     + H.gdrive_models_path+'\"'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaHtiscM8hld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set img input method\n",
        "H.img_input_method=\"dataset\"        #@param ['raw','gallery-dl','dataset']\n",
        "# set new or re train\n",
        "H.pretrained_or_new_model='new' #@param ['new','pre']\n",
        "# name of the dataset\n",
        "H.dataset_name='catsanddogs'         #@param {type : \"string\"}\n",
        "# size\n",
        "H.resize_value=32              #@param {type : \"\"}\n",
        "# epochs\n",
        "H.epochs_value=1              #@param {type : \"\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B8UgmRBzmhQA"
      },
      "source": [
        "## Process a folder of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rly433VrN31O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V-nlYwkO0RK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "if (H.img_input_method =='raw'):\n",
        "    print('This inits function ProcessRawImgFolder')\n",
        "    ProcessRawImgFolder()\n",
        "    \n",
        "if(H.img_input_method =='dataset'):\n",
        "    FetchSet()\n",
        "    \n",
        "def ProcessRawImgFolder():   \n",
        "    # size\n",
        "#     H.resize_value=256\n",
        "    # get drive files\n",
        "    get_gdrive_dataset(H.dataset_name+'.zip','raw_img_data','raw_image_packs')\n",
        "\n",
        "    # mangafaces fix\n",
        "    if H.dataset_name == 'mangafaces':\n",
        "        # images are in folder data and need to be in mangafaces\n",
        "        H.Me(['cml','mkdir -p /content/installed_reps/piss-ant-pix2pix/raw_img_data/'+H.dataset_name])\n",
        "        H.Me(['cml','cp -r /content/installed_reps/piss-ant-pix2pix/raw_img_data/data/* /content/installed_reps/piss-ant-pix2pix/raw_img_data/'+H.dataset_name])\n",
        "        H.Me(['cml','rm -r /content/installed_reps/piss-ant-pix2pix/raw_img_data/data'])\n",
        "\n",
        "      # set path to images to process\n",
        "    IntoPath=H.local_raw_imgs_path + H.dataset_name\n",
        "    H.img_path=Path(IntoPath)\n",
        "\n",
        "    # goto pix root\n",
        "    os.chdir(H.pix_root)\n",
        "    print('Image folder set to '+str(IntoPath))\n",
        "\n",
        "    # glob the folder for images\n",
        "    H.prepro_img_list=H.Me(['globx',IntoPath,'*.png'])\n",
        "    print(len(H.prepro_img_list),end=' ')\n",
        "    print(' Images Found!')\n",
        "\n",
        "    # make the processing folders \n",
        "    H.Me(['mkd',['_blank', '_edged', '_resized', '_combined_blank', '_combined_edged'], H.pix_root+'p2p_process_tmp'])\n",
        "    # make the dataset folders\n",
        "    H.Me(['mkd',['_resize_edged_combined', '_resize_blank_combined', '_resized', '_edged', '_blank'], H.local_datasets_path+H.dataset_name])\n",
        "    # process\n",
        "    H.Me(['cml','python tools/process.py --input_dir '+IntoPath+' --operation resize --size '+str(H.resize_value)+' --output_dir '+H.pix_root+'p2p_process_tmp/_resized/'])\n",
        "    H.Me(['cml','python tools/process.py --input_dir '+H.pix_root+'p2p_process_tmp/_resized --operation blank --output_dir '+H.pix_root+'p2p_process_tmp/_blank'])\n",
        "    H.Me(['cml','python tools/edge.py    --input_dir '+H.pix_root+'p2p_process_tmp/_resized --output_dir '+H.pix_root+'p2p_process_tmp/_edged'])\n",
        "    # combine A/B\n",
        "    H.Me(['cml','python tools/process.py --input_dir '+H.pix_root+'p2p_process_tmp/_resized --b_dir '+H.pix_root+'p2p_process_tmp/_edged --operation combine --output_dir '+H.pix_root+'p2p_process_tmp/_combined_edged'])\n",
        "    H.Me(['cml','python tools/process.py --input_dir '+H.pix_root+'p2p_process_tmp/_resized --b_dir '+H.pix_root+'p2p_process_tmp/_blank --operation combine --output_dir '+H.pix_root+'p2p_process_tmp/_combined_blank'])\n",
        "    # split\n",
        "    H.Me(['cml','python tools/split.py --dir '+H.pix_root+'p2p_process_tmp/_combined_edged'])\n",
        "    H.Me(['cml','python tools/split.py --dir '+H.pix_root+'p2p_process_tmp/_combined_blank'])\n",
        "    H.Me(['cml','python tools/split.py --dir '+H.pix_root+'p2p_process_tmp/_resized'])\n",
        "    H.Me(['cml','python tools/split.py --dir '+H.pix_root+'p2p_process_tmp/_blank'])\n",
        "    H.Me(['cml','python tools/split.py --dir '+H.pix_root+'p2p_process_tmp/_edged'])\n",
        "    # copy over to permanent datasets folder\n",
        "    H.Me(['cml','cp -rf '+H.pix_root+'p2p_process_tmp/_resized/* '+H.local_datasets_path+H.dataset_name+'/_resized/'])\n",
        "    H.Me(['cml','cp -rf '+H.pix_root+'p2p_process_tmp/_edged/* '+H.local_datasets_path+H.dataset_name+'/_edged/'])\n",
        "    H.Me(['cml','cp -rf '+H.pix_root+'p2p_process_tmp/_blank/* '+H.local_datasets_path+H.dataset_name+'/_blank/'])\n",
        "    H.Me(['cml','cp -rf '+H.pix_root+'p2p_process_tmp/_combined_edged/* '+H.local_datasets_path+H.dataset_name+'/_resize_edged_combined/'])\n",
        "    H.Me(['cml','cp -rf '+H.pix_root+'p2p_process_tmp/_combined_blank/* '+H.local_datasets_path+H.dataset_name+'/_resize_blank_combined/'])\n",
        "    # set as active set\n",
        "    H.ActiveSetPath = H.local_datasets_path+H.dataset_name+'/_resize_edged_combined/'\n",
        "    # zip set to gdrive\n",
        "    os.chdir(H.local_datasets_path+H.dataset_name)\n",
        "    H.Me(['cml','zip -r \"'+H.gdrive_datasets_path+H.dataset_name+'_set.zip\" ./*'])\n",
        "    os.chdir(H.pix_root)\n",
        "    RunWithNewBrain()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3sR9cE4GISj",
        "colab_type": "text"
      },
      "source": [
        "## Load a pre processed set from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gKw8uNwGOIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# H.dataset_name='cityscapes_set'\n",
        "# get_gdrive_dataset(H.dataset_name+'.zip','datasets','/content/drive/My Drive/datasets/')\n",
        "# result=H.Me(['vdir'])\n",
        "# H.local_dataset_root + H.dataset_name\n",
        "# print(H.method_args)\n",
        "# print(result)\n",
        "\n",
        "\n",
        "# H.dataset_name='elvis_edged_set'\n",
        "# get_gdrive_dataset(H.dataset_name+'.zip','datasets','/content/drive/My Drive/datasets/')\n",
        "# result=H.Me(['vdir'])\n",
        "# H.local_dataset_root + H.dataset_name\n",
        "# print(H.method_args)\n",
        "# print(result)\n",
        "\n",
        "# H.dataset_name='elvis_edged_set'\n",
        "# get_gdrive_dataset(H.dataset_name+'.zip','datasets/elvis','/content/drive/My Drive/datasets/')\n",
        "# result=H.Me(['vdir'])\n",
        "# H.local_dataset_root + H.dataset_name\n",
        "# print(H.method_args)\n",
        "# print(result)\n",
        "\n",
        "\n",
        "# # dataset\n",
        "# H.dataset_name='pail'\n",
        "# !mkdir -p {H.pix_root}dataset_test\n",
        "# get_gdrive_dataset('/content/drive/My Drive/Colab Notebooks/datasets/'+H.dataset_name+'_datasets.zip','dataset_test')\n",
        "# H.dataset_path=Path(H.ActiveSetPath)\n",
        "# H.Me(['cml','cp -rf '+H.pix_root+'/dataset_test/content/installed_reps/piss-ant-pix2pix/dataset_test/* '+ H.ActiveSetPath+'/'])\n",
        "# # H.Me(['cml','rm -r /content/installed_reps/piss-ant-pix2pix/dataset_test/content '])\n",
        "# Zip the model to gdrive\n",
        " print(H.gdrive_models_path+H.dataset_name+'_model_training.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nu7u-TKvuO8M"
      },
      "source": [
        "## Load pretrained model and dataset files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yjs0mjzmuO8Q",
        "colab": {}
      },
      "source": [
        "def FetchSet():\n",
        "    # get the preprocessed dataset\n",
        "#     H.dataset_name='insect'\n",
        "    get_gdrive_dataset(H.dataset_name+'_set.zip','datasets','datasets')\n",
        "    H.ActiveSetPath=H.local_datasets_path + H.dataset_name+'/_resize_edged_combined/train'\n",
        "    H.dataset_path=Path(H.ActiveSetPath)\n",
        "    # count the images in combine folder\n",
        "    H.check_image_folder=H.Me(['globx',H.ActiveSetPath,'*.png'])\n",
        "    count=len(H.check_image_folder)\n",
        "    if count > 0:\n",
        "        print(count,end=' ')\n",
        "        print(' Images Found!')\n",
        "        if H.pretrained_or_new_model == 'pre':\n",
        "            # download pretrained brain\n",
        "            H.BrainZipFile=H.dataset_name+'_model_training.zip'\n",
        "            f=PATH(H.gdrive_models_path+H.dataset_name+'_model_training.zip')\n",
        "            if not f.is_file():\n",
        "                print('The brain ('+H.BrainZipFile+') is not found!')\n",
        "                exit()\n",
        "            else:\n",
        "                print(\"Found the brain ('+H.BrainZipFile+') fetching it now from gdrive!\")\n",
        "                FetchModel()\n",
        "        else:\n",
        "            RunWithNewBrain()\n",
        "\n",
        "def FetchModel():\n",
        "    # getting the file from gdrive\n",
        "    get_gdrive_dataset(H.dataset_name+'_model_training.zip','models','models')\n",
        "    H.ActiveModelPath=H.pix_root +'models/'+H.dataset_name+'/model'\n",
        "    # see if the index.html is working\n",
        "    os.chdir(H.pix_root +'models/'+H.dataset_name+'/model')\n",
        "    display.display(display.HTML('index.html'))  \n",
        "    os.chdir(H.pix_root)\n",
        "    \n",
        "def RunWithNewBrain():\n",
        "    # Load Tensorboard\n",
        "    from tensorboard import notebook\n",
        "#     notebook.list()\n",
        "    %reload_ext tensorboard\n",
        "    import tensorflow as tf\n",
        "    %tensorboard --logdir {output_folder}\n",
        "    \n",
        "    training_epochs=H.epochs_value\n",
        "    mode='train'\n",
        "    direction='BtoA'\n",
        "    lr=5e-05\n",
        "    print('Learn rate set on '+ str('{:f}'.format(lr)))\n",
        "    # lr = 9.12E-04\n",
        "    !python pix2pix.py  --mode {mode} --batch_size 2 --summary_freq 10 --progress_freq 10 --save_freq 50 --display_freq 10 --output_dir {output_folder} --max_epochs {str(training_epochs)} --input_dir {input_folder} --which_direction {direction}\n",
        "    # H.Me(['cml','python pix2pix.py  --mode '+mode+' --batch_size 4 --summary_freq 1 --progress_freq 10 --save_freq 100 --display_freq 10 --output_dir '+output_folder+' --max_epochs '+str(training_epochs)+' --input_dir '+input_folder+' --which_direction '+direction])\n",
        "    # zip To gdrive\n",
        "    os.chdir('cd /content/installed_reps/piss-ant-pix2pix/models')\n",
        "    H.Me(['cml','zip -r \"'+H.gdrive_root+'/models/'+H.dataset_name+'_'+str(training_epochs)+'_epoch_training.zip\" ./*'])\n",
        "    print('Trained Brain was saved under  ' + H.gdrive_root+'/models/'+H.dataset_name+'_'+str(training_epochs)+'_epoch_training.zip')\n",
        "      \n",
        "def RunWithPretrainedBrain():\n",
        "    # Load Tensorboard\n",
        "    from tensorboard import notebook\n",
        "#     notebook.list()\n",
        "    %reload_ext tensorboard\n",
        "    import tensorflow as tf\n",
        "    %tensorboard --logdir {output_folder}\n",
        "    # not doing real epochs but for loop on 2 epochs then zipping to gdrive because of banning and disconnecting\n",
        "    for i in range(H.epochs_value):\n",
        "        training_epochs=2\n",
        "        mode='train'\n",
        "        direction='BtoA'\n",
        "        lr=5e-05\n",
        "        lr2 = 9.12E-04\n",
        "        print( 'Learn rate set on ' + \"%.6f\" % float(lr2))\n",
        "        # get the checkpoint dir\n",
        "        start_with_checkpoint = '--checkpoint '+output_folder # '+with_checkpoint+' \n",
        "\n",
        "        !python pix2pix.py {start_with_checkpoint} --mode {mode} --batch_size 2 --summary_freq 10 --progress_freq 10 --save_freq 50 --display_freq 10 --output_dir {output_folder} --max_epochs {str(training_epochs)} --input_dir {input_folder} --which_direction {direction}\n",
        "        # H.Me(['cml','python pix2pix.py '+start_with_checkpoint+' --mode '+mode+' --batch_size 16 --summary_freq 50 --progress_freq 100 --save_freq 100 --display_freq 5 --output_dir '+output_folder+' --max_epochs '+str(training_epochs)+' --input_dir '+input_folder+' --which_direction '+direction])\n",
        "        # zipping to gdrive\n",
        "        os.chdir('cd /content/installed_reps/piss-ant-pix2pix/models')\n",
        "        H.Me(['cml','zip -r \"'+H.gdrive_root+'/models/'+H.dataset_name+'_'+str(training_epochs)+'_epoch_training.zip\" ./*'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KLrCjcz4XQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAIN!!!!!\n",
        "output_folder=H.pix_root+'models/'+H.dataset_name+'/model'\n",
        "input_folder = H.ActiveSetPath"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf-A5YY9su6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "lr=5e-05\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDZHM6k9axFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# print(H.ActiveSetPath)\n",
        "# H.Me(['vdir'])\n",
        "from tensorboard import notebook\n",
        "notebook.list()\n",
        "%reload_ext tensorboard\n",
        "import tensorflow as tf\n",
        "%tensorboard --logdir {output_folder}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I80S_6gs0Skh",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTbz8OKxH7K3",
        "colab_type": "text"
      },
      "source": [
        "### help\n",
        ">['aspect_ratio = 1.0',\n",
        " 'batch_size = 16',\n",
        " 'beta1 = 0.5',\n",
        " 'checkpoint = /content/installed_reps/piss-ant-pix2pix/garbagepailkids_resize/training',\n",
        " 'display_freq = 1',\n",
        " 'flip = True',\n",
        " 'gan_weight = 1.0',\n",
        " 'input_dir = /content/installed_reps/piss-ant-pix2pix/garbagepailkids_resize/_combined/train',\n",
        " 'l1_weight = 0.0',\n",
        " 'lab_colorization = False',\n",
        " 'lr = 5e-05',\n",
        " 'max_epochs = 10',\n",
        " 'max_steps = None',\n",
        " 'mode = train',\n",
        " 'ndf = 64',\n",
        " 'ngf = 64',\n",
        " 'output_dir = /content/installed_reps/piss-ant-pix2pix/garbagepailkids_resize/training',\n",
        " 'patch_gan = 1',\n",
        " 'progress_freq = 1',\n",
        " 'save_freq = 100',\n",
        " 'scale_size = 266',\n",
        " 'seed = 0',\n",
        " 'skip_connection = 1',\n",
        " 'summary_freq = 1',\n",
        " 'trace_freq = 0',\n",
        " 'wgan = 1',\n",
        " 'which_direction = BtoA',\n",
        " '/content/installed_reps/piss-ant-pix2pix/garbagepailkids_resize/_combined/train']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edHmUBDcgQsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_epochs=5\n",
        "mode='train'\n",
        "direction='BtoA'\n",
        "lr=5e-05\n",
        "# lr = 9.12E-04\n",
        "!python pix2pix.py  --mode {mode} --batch_size 4 --summary_freq 10 --progress_freq 10 --save_freq 10 --display_freq 10 --output_dir {output_folder} --max_epochs {str(training_epochs)} --input_dir {input_folder} --which_direction {direction}\n",
        "\n",
        "# H.Me(['cml','python pix2pix.py  --mode '+mode+' --batch_size 4 --summary_freq 1 --progress_freq 10 --save_freq 100 --display_freq 10 --output_dir '+output_folder+' --max_epochs '+str(training_epochs)+' --input_dir '+input_folder+' --which_direction '+direction])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl3OYkIM3uvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "H.Me(['cml','zip -r \"'+H.gdrive_root+'/models/'+H.dataset_name+'_'+str(training_epochs)+'_epoch_training.zip\" '+output_folder+'/*'])\n",
        "%tensorboard --logdir={output_folder}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG7gQ7UXwmWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "training_epochs=10\n",
        "mode='train'\n",
        "direction='BtoA'\n",
        "lr=5e-05\n",
        "# lr = 9.12E-04\n",
        "# get the checkpoint dir\n",
        "\n",
        "\n",
        "start_with_checkpoint = '--checkpoint '+output_folder # '+with_checkpoint+' \n",
        "\n",
        "!python pix2pix.py {start_with_checkpoint} --mode {mode} --batch_size 4 --summary_freq 10 --progress_freq 10 --save_freq 10 --display_freq 10 --output_dir {output_folder} --max_epochs {str(training_epochs)} --input_dir {input_folder} --which_direction {direction}\n",
        "\n",
        "# H.Me(['cml','python pix2pix.py '+start_with_checkpoint+' --mode '+mode+' --batch_size 16 --summary_freq 50 --progress_freq 100 --save_freq 100 --display_freq 5 --output_dir '+output_folder+' --max_epochs '+str(training_epochs)+' --input_dir '+input_folder+' --which_direction '+direction])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UstJjoDXxYdg",
        "colab": {}
      },
      "source": [
        "# Zip the model to gdrive\n",
        "H.Me(['cml','zip -r \"'+H.gdrive_root+'/models/'+H.dataset_name+'_'+str(training_epochs)+'_epoch_training.zip\" '+output_folder+'/*'])\n",
        "# H.Me(['cml','unzip \"'+H.gdrive_root+'/models/'+H.dataset_name+'_'+str(training_epochs)+'_epoch_training.zip\" -d '+output_folder+'_pretrained'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFIvyJXLf6uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "%cd /content/installed_reps/piss-ant-pix2pix/models\n",
        "H.Me(['cml','zip -r \"'+H.gdrive_root+'/models/'+H.dataset_name+'_'+str(training_epochs)+'_epoch_training.zip\" ./*'])\n",
        "\n",
        "# checkpoints\n",
        "# /content/drive/My\\\\ Drive/Colab\\\\ Notebooks/pretrained_models/apes_1_epoch_training.zip\n",
        "# stored_models=H.Me(['globx',output_folder,'*outputs.png'])\n",
        "# print(stored_models)\n",
        "# !ls -l /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'_resize/training_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nczfhLOklxn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://live.staticflickr.com/2936/33549790582_48a514baed_b.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5DaOKxDkKcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# /content/installed_resp/piss-ant-pix2pix/33549790582_48a514baed_b.jpg\n",
        "# !python pix2pix.py --mode test --output_dir /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'_resize/test --input_dir /content/installed_resp/piss-ant-pix2pix --seed 0 --checkpoint /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'_resize/training_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNvU9s7djrZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the complete model\n",
        "# !python /content/installed_resp/piss-ant-pix2pix/server/tools/export-checkpoint.py --checkpoint /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'_resize/_combined/train --output_file /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'_resize/training_train/'+H.pix_root+'_BtoA_model_save.bin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxYR6zLkqpIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# # store zip to drive\n",
        "# !zip /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'/* /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'_original_images.zip\n",
        "# !zip /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'_resize/_combined/* /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'_dataset.zip\n",
        "# !zip /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'_resize/training_train/'+H.pix_root+'_BtoA_model_save.bin /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'_model_bin.zip\n",
        "# !zip /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'_resize/training_train/* /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'.zip\n",
        "\n",
        "# %cd /content/drive/My\\ Drive/Colab\\ Notebooks/Best_Colabs\n",
        "# !cp /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'_original_images.zip '+H.pix_root+'_original_images.zip\n",
        "# !cp /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'_dataset.zip ./'+H.pix_root+'_dataset.zip\n",
        "# !cp /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'_model_bin.zip ./'+H.pix_root+'_model_bin.zip\n",
        "# !cp /content/installed_resp/piss-ant-pix2pix/'+H.pix_root+'.zip ./'+H.pix_root+'.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvAeYpopjrvD",
        "colab_type": "text"
      },
      "source": [
        "## pretrained\n"
      ]
    }
  ]
}