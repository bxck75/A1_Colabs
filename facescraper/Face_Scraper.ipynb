{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bxck75/A1_Colabs/blob/master/facescraper/Face_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bxck75/Face_Zoo.git"
      ],
      "metadata": {
        "id": "Ihogf4AvNQbN",
        "outputId": "bb921eed-c066-447f-f98c-4e1ba4288422",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Face_Zoo'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 22 (delta 0), reused 3 (delta 0), pack-reused 19\u001b[K\n",
            "Unpacking objects: 100% (22/22), 1.43 MiB | 3.46 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SaYHHr0ENXsW",
        "outputId": "e55b826b-2a79-4320-98d8-e25ed211187b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os,sys,cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image \n",
        "import PIL \n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QGnq3y_gOdd5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "haar_path = '/content/Face_Zoo'"
      ],
      "metadata": {
        "id": "2kHR0SOVOMLR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_detector=cv2.CascadeClassifier(os.path.join(haar_path,'haarcascade_frontalface_default.xml'))\n",
        "eye_detector = cv2.CascadeClassifier(os.path.join(haar_path,'haarcascade_eye.xml'))\n"
      ],
      "metadata": {
        "id": "lgCutE8FOEcV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get a groupfoto from internet\n",
        "and read it"
      ],
      "metadata": {
        "id": "hkY3ZZDAQLyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://www.thesun.ie/wp-content/uploads/sites/3/2017/02/nintchdbpict000299847684-1.jpg -o group2.jpg\n",
        "!curl https://i2-prod.walesonline.co.uk/incoming/article9265299.ece/ALTERNATES/s1227b/JS62775250.jpg -o group1.jpg\n",
        "img = cv2.imread('group2.jpg')"
      ],
      "metadata": {
        "id": "S0I3wSaePRaR",
        "outputId": "87586533-4a63-4d2b-d335-5adb1ccd069a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2201k  100 2201k    0     0  1070k      0  0:00:02  0:00:02 --:--:-- 1070k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  550k  100  550k    0     0   545k      0  0:00:01  0:00:01 --:--:--  545k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
        "faces_result = face_detector.detectMultiScale(gray, 1.3, 5) \n",
        "for (x,y,w,h) in faces_result: \n",
        "  img = cv2.rectangle(img,(x,y),(x+w,y+h),(300,0,0),2) \n",
        "  roi_gray = gray[y:y+h, x:x+w] \n",
        "  roi_color = img[y:y+h, x:x+w] \n",
        "  cv2_imshow(roi_color)\n",
        "#  eyes = eye_detector.detectMultiScale(roi_gray) \n",
        "#  for (ex,ey,ew,eh) in eyes: \n",
        "#    cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
        "\n",
        "cv2_imshow(img) \n",
        "cv2.waitKey(0) \n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "-wONhKKVOt8D"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "img = cv2.imread(\"path/to/img.png\")\n",
        "\n",
        "# You may need to convert the color.\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "im_pil = Image.fromarray(img)\n",
        "\n",
        "# For reversing the operation:\n",
        "im_np = np.asarray(im_pil)"
      ],
      "metadata": {
        "id": "TPczeGfAU14A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing OpenCV in Python\n",
        "OpenCV can be installed using the pip package manager in python.\n",
        "\n",
        "!pip install opencv-python\n",
        "#---OR ---\n",
        "!pip install opencv-contrib-python\n",
        "Loading Haar-cascade in OpenCV\n",
        "We can load haar-cascade XML files using cv2.CascadeClassifier function.\n",
        "\n",
        "face_detector=cv2.CascadeClassifier(‘haarcascade_frontalface_default.xml’)\n",
        "eye_dectector = cv2.CascadeClassifier(‘haarcascade_eye.xml’)\n",
        "We can call the detector function once the XML file is loaded.\n",
        "\n",
        "results = face_detector.detectMultiScale(gray_img, scaleFactor=1.15,minNeighbors=5,minSize=(34, 35), flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "\n",
        "results It is the list of bounding box coordinates (x,y,w,h) around the detected object.\n",
        "\n",
        "Parameters in detectMultiScale\n",
        "\n",
        "scaleFactor – This tells how much the object’s size is reduced to the original image.\n",
        "minNeighbors – This parameter tells how many neighbors should contribute in a single bounding box.\n",
        "minSize — This signifies the minimum possible size of the object in our image. if our object is smaller than the minSize it will be ignored.\n",
        "Note : For Object detection, we must use a gray_image , minNeighbors,scaleFactorther parameters are not necessary.\n",
        "\n",
        "Face Detection of the Humans\n",
        "Let’s take the first example of object detection using a pre-trained haar cascade, where we will detect human faces from a picture using Python.\n",
        "\n",
        "Download the cascade file for face detection using this link.\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "#---loading the Haar Cascade detector using CascadeClassifier---face_detector=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "#---Loading the image from local -----\n",
        "img = cv2.imread('team_india.jpg')\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "results = face_detector.detectMultiScale(gray, 1.3, 5)\n",
        "for (x,y,w,h) in results:\n",
        "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
        "  \n",
        "cv2.imshow('img',img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "results It contains the coordinate of the Bounding boxes in the picture.\n",
        "detectMultiScale This method only works on grayscale pictures.\n",
        "cv2.rectangle This OpenCV method allows us to draw rectangles after passing the coordinates.\n",
        "scaleFactor = 1.3 FineTuning parameter from 1 to 2.\n",
        "face detection\n",
        "Hierarchical detection\n",
        "Haarcascade supports Hierarchical detection, which means the Haar cascade can be able to detect multiple objects within a single frame in a hierarchical manner.\n",
        "\n",
        "Suppose we have to detect the faces and eyes of humans. To proceed with the task, we need to follow these steps.\n",
        "\n",
        "Detect Faces\n",
        "For every face, crop faces and forward them for eye detection\n",
        "After finding the coordinates of the eyes (ex,ey,ew,eh) draw a bounding box around the eyes in the original picture.\n",
        "draw a bounding box around faces using coordinates(x,y,w,h) on the original picture.\n",
        "import numpy as np\n",
        "import cv2\n",
        "face_detector1=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "eye_detector1 = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "img = cv2.imread('uman.jpg')\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "faces_result = face_detector.detectMultiScale(gray, 1.3, 5)\n",
        "for (x,y,w,h) in faces_result:\n",
        "img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "roi_gray = gray[y:y+h, x:x+w]\n",
        "roi_color = img[y:y+h, x:x+w]\n",
        "eyes = eye_detector.detectMultiScale(roi_gray)\n",
        "for (ex,ey,ew,eh) in eyes:\n",
        "cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
        "\n",
        "cv2.imshow('img',img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "face detection\n",
        "Implementing Face Detection in Real Time\n",
        "Object detection using Haar Cascade can be used in OpenCV video stream, we only need to read a video or camera feed in OpenCV, and the rest of the thing will be the same.\n",
        "\n",
        "A Video feed is a sequence of frames so that the code will be the same as the single frame. Due to its light computation requirements, Haar Cascade runs at a good time per second.\n",
        "\n",
        "We will read OpenCV video cam feed input to take images in real-time.\n",
        "\n",
        "import cv2\n",
        "face_detector1 = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "eye_dectector1 = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "# reading the input image now\n",
        "cap = cv2.VideoCapture(0)\n",
        "while cap.isOpened():\n",
        "    _, frame = cap.read()\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_detector1.detectMultiScale(gray,1.1, 4 )\n",
        "    for (x,y, w, h) in faces:\n",
        "    cv2.rectangle(frame, pt1 = (x,y),pt2 = (x+w, y+h), color = (255,0,0),thickness =  3)\n",
        "    roi_gray = gray[y:y+h,x:x+w]\n",
        "    roi_color = frame[y:y+h, x:x+w]\n",
        "    eyes = eye_dectector1.detectMultiScale(roi_gray)\n",
        "    for (ex,ey, ew, eh) in eyes:\n",
        "        cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0,255,0), 5)\n",
        "    cv2.imshow(\"window\", frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "frame.release()\n",
        "The bounding boxes for the eyes and faces will be real-time and change for every frame.\n",
        "\n",
        "Limitation of Haar Cascade Face Detection\n",
        "Haar Cascade is still very popular for some objects like faces, cars, etc., where the object is easily distinguishable.\n",
        "\n",
        "Haar Cascade can’t work for deep object detection like types of grain, etc.\n",
        "\n",
        "There are a few Limitations of the Haar Cascade Algorithm-\n",
        "\n",
        "Lower Accuracy compared to modern object detectors.\n",
        "High False-positive detection.\n",
        "Manual tuning of parameters is required.\n",
        "Training haar cascade for the custom objects is not easy at all.\n",
        "Conclusion\n",
        "In this article, we have talked about the working of the haar cascade and how to implement the haar cascade for object detection using OpenCV in python. We used a pre-trained haar cascade file for face detection and eyes detection, and then we performed the same operation in real time.\n",
        "\n",
        "We also talked about the limitation of the haar cascade algorithm, why it is still widely used, and why it is so fast.\n",
        "\n",
        "The false positive rate can be fixed using manual parameter tuning.\n",
        "YOLO, SSD, and other deep learning object detection algorithms promise better accuracy.\n",
        "Training customer haar cascade is time-consuming and inefficient.\n",
        "Thanks for reading, If you still have any queries feel free to write me on LinkedIn.\n",
        "\n",
        "The media shown in this article is not owned by Analytics Vidhya and is used at the Author’s discretion."
      ],
      "metadata": {
        "id": "I_TXXAd_N8wz"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}