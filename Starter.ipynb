{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Starter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bxck75/A1_Colabs/blob/master/Starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0LLcpX9j8SS",
        "colab_type": "text"
      },
      "source": [
        "# Main load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx2zQaRe5DUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os,subprocess, re\n",
        "\n",
        "# system functions\n",
        "def recursive_glob(treeroot, pattern):\n",
        "  results = []\n",
        "  for base, dirs, files in os.walk(treeroot):\n",
        "    goodfiles = fnmatch.filter(files, pattern)\n",
        "    results.extend(os.path.join(base, f) for f in goodfiles)\n",
        "  return results\n",
        "\n",
        "def cmdline(cmd,pr=False):\n",
        "  result =[]\n",
        "  f = os.popen(cmd)\n",
        "  try:\n",
        "    for line in f:\n",
        "      if pr == True:\n",
        "        print(line)\n",
        "        result.append(line),\n",
        "  finally:\n",
        "    f.close()\n",
        "  return result\n",
        "\n",
        "# stinking default folder...poef!\n",
        "cmdline('rm -r /content/sample_data')\n",
        "# cmdline('pip install gitpython')\n",
        "# pick fs\n",
        "filesystem = \"local\"\n",
        "if filesystem == 'gdrive':\n",
        "  # sync google drive\n",
        "  from google.colab import drive\n",
        "  import os\n",
        "  # if drive is needed uncomment\n",
        "  print('Google drive ',end='')\n",
        "  drive.mount('/content/drive',force_remount=True)\n",
        "  print('Root folder set to ',end='')\n",
        "  root = '/content/drive/My drive/image_learning'\n",
        "  print(root)\n",
        "else:\n",
        "  print('Root folder set to ',end='')\n",
        "  root = '/content/image_learning'\n",
        "  print(root) \n",
        "\n",
        "#shoot root\n",
        "os.makedirs(root,exist_ok = True)\n",
        "os.chdir(root)\n",
        "\n",
        "# install missing libs\n",
        "cmdline('pip install sklearn imageio tensorflow-gpu==2.0.0-alpha0')\n",
        "cmdline('apt install tree')\n",
        "cmdline('pip install -q --upgrade --force-reinstall tensorflow-gpu')\n",
        "\n",
        "# import the rest\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D,MaxPooling2D\n",
        "from keras.optimizers import SGD, RMSprop,adam\n",
        "from keras.utils import np_utils\n",
        "import theano, glob, shutil, fnmatch, time, cv2, itertools\n",
        "from IPython.display import clear_output, display, Image\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import ipywidgets as widgets\n",
        "from subprocess import PIPE, Popen\n",
        "import tensorflow as tf\n",
        "\n",
        "# list of reps uncomment to install\n",
        "reps=[\n",
        "#         'drallensmith/neat-python',\n",
        "#         'CodeReclaimers/neat-python',\n",
        "#         'uber-research/deep-neuroevolution',\n",
        "#         'MorvanZhou/Evolutionary-Algorithm',\n",
        "#         'llSourcell/blockchain-python-tutorial',\n",
        "#         'llSourcell/autoencoder_demo',\n",
        "#         'llSourcell/autoencoder_explained',\n",
        "#         'llSourcell/awesome-public-datasets',\n",
        "#         'llSourcell/7_Research_Directions_Deep_Learning',\n",
        "#         'hardmaru/sketch-rnn',\n",
        "#         'hardmaru/sketch-rnn-datasets',\n",
        "#         'hardmaru/sketch-rnn-poste',\n",
        "#         'Gogul09/virtual-drum',\n",
        "#         'ytdl-org/youtube-dl',\n",
        "#         'nnUyi/GAN-Collections',\n",
        "#         'carpedm20/BEGAN-tensorflow',\n",
        "        'mikf/gallery-dl',\n",
        "#         'NVlabs/stylegan',\n",
        "#         'mauriceling/dose',\n",
        "#         'corenel/Realistic-Neural-Talking-Head-Models',\n",
        "        'bxck75/piss-ant-pix2pix',\n",
        "#         'bxck75/datasets',\n",
        "#         'hardmaru/estool',\n",
        "#         'deepmipt/DeepPavlov',\n",
        "#         'bxck75/A1_Colabs',\n",
        "#         'tjwei/Flappy-Turtle.',\n",
        "#         'tjwei/fonttools',\n",
        "#         'tjwei/blender3d_import_psk_psa',\n",
        "#         'lllyasviel/sketchKeras',\n",
        "#         'Mckinsey666/Anime-Face-Dataset',\n",
        "#         'chenyuntc/pytorch-book',\n",
        "#         'lllyasviel/style2paints',\n",
        "#         'llSourcell/GANS-for-style-transfer',\n",
        "#         'opencv/open_model_zoo',\n",
        "#         'hindupuravinash/the-gan-zoo',\n",
        "#         'corenel/GAN-Zoo',\n",
        "#         'eriklindernoren/Keras-GAN',\n",
        "#         'junyanz/CycleGAN',\n",
        "#         'junyanz/pytorch-CycleGAN-and-pix2pix',\n",
        "#         'junyanz/iGAN', #----> !wget http://efrosgans.eecs.berkeley.edu/iGAN/datasets/church_64.zip <----dataset \toutdoor_128.zip \thandbag_128.zip !!!\n",
        "#         'martinarjovsky/WassersteinGAN',\n",
        "#         'shaoanlu/faceswap-GAN',\n",
        "#         'LantaoYu/SeqGAN',\n",
        "#         'tjwei/GANotebooks',\n",
        "#         'adeshpande3/Tensorflow-Programs-and-Tutorials',\n",
        "#         'adeshpande3/Generative-Adversarial-Networks',\n",
        "#         'adeshpande3/KaggleGhosts',\n",
        "#         'adeshpande3/OpenAI_Gym_Universe',\n",
        "#         'diegoalejogm/gans',\n",
        "#         'osh/KerasGAN',\n",
        "#         'r9y9/gantts',\n",
        "#         'jayleicn/animeGAN',\n",
        "#         'jayleicn/ImageNet-Training',\n",
        "#         'Zardinality/WGAN-tensorflow',\n",
        "#         'tree-gan/BonsaiNet',\n",
        "#         'RossMcKenzie/TreeGAN',\n",
        "#         'carpedm20/BEGAN-tensorflow',\n",
        "#         'martinarjovsky/WassersteinGAN',\n",
        "#         'timsainb/Tensorflow-MultiGPU-VAE-GAN',\n",
        "#         'Larox/python-moviepy-meetup',\n",
        "#         'tjwei/keras-yolo3',\n",
        "#         'tensorflow/gan',\n",
        "#         'tensorflow/moonlight'\n",
        "#         'tensorflow/models',\n",
        "#         'tensorflow/datasets',\n",
        "#         'tensorflow/docs',\n",
        "#         'mnicnc404/CartoonGan-tensorflow',\n",
        "#         'Yijunmaverick/CartoonGAN-Test-Pytorch-Torch',\n",
        "#         'keras-team/keras-contrib',\n",
        "#         'mnicnc404/CartoonGan-tensorflow',\n",
        "]\n",
        "\n",
        "def findFilesInFolderYield(path,  extension, containsTxt='', subFolders = True, excludeText = ''):\n",
        "\n",
        "    if type(containsTxt) == str: # if a string and not in a list\n",
        "        containsTxt = [containsTxt]\n",
        "\n",
        "    myregexobj = re.compile('\\.' + extension + '$')    # Makes sure the file extension is at the end and is preceded by a .\n",
        "    try:   # Trapping a OSError or FileNotFoundError:  File permissions problem I believe\n",
        "        for entry in os.scandir(path):\n",
        "            if entry.is_file() and myregexobj.search(entry.path): # \n",
        "                bools = [True for txt in containsTxt if txt in entry.path and (excludeText == '' or excludeText not in entry.path)]\n",
        "                if len(bools)== len(containsTxt):\n",
        "                    yield entry.stat().st_size, entry.stat().st_atime_ns, entry.stat().st_mtime_ns, entry.stat().st_ctime_ns, entry.path\n",
        "            elif entry.is_dir() and subFolders:   # if its a directory, then repeat process as a nested function\n",
        "                yield from findFilesInFolderYield(entry.path,  extension, containsTxt, subFolders)\n",
        "    except OSError as ose:\n",
        "        print('Cannot access ' + path +'. Probably a permissions error ', ose)\n",
        "    except FileNotFoundError as fnf:\n",
        "        print(path +' not found ', fnf)        \n",
        "# Gitgo class\n",
        "class GitGo(): \n",
        "  def __init__(self,repos,sub_repos=False,chdir=True,path='/content/'):\n",
        "    self.sub_repo_list = []\n",
        "    self.GitUsers=[]\n",
        "    self.repos = repos\n",
        "    self.chdir = chdir\n",
        "    self.path = path\n",
        "    os.makedirs(self.path, exist_ok = True)\n",
        "    if 'help' in self.repos:\n",
        "      self.help()\n",
        "    self.pull_reps()\n",
        "    self.custom_reps_setup()\n",
        "    if sub_repos == True:\n",
        "      self.get_other_reps()\n",
        "  def help(self):\n",
        "    return \"* pulls git rep and shows files \\\n",
        "            * returns root path for the repository \\\n",
        "            * Function needs repository <user>/<repository name> combination\\\n",
        "            * Switch chdir and define the rootpath for the repository\\\n",
        "            * Use : GitGo(<list of reps to install>, sub_repos=<True/False, chdir=<True/False>, path=<root path>)\\\n",
        "    #--pull al selected reps  \n",
        "  def pull_reps(self):    \n",
        "    for rep in self.repos:\n",
        "      self.rep=rep.split('/')\n",
        "      # change folder check\n",
        "      if self.chdir ==True:\n",
        "        #Switch to path\n",
        "        os.chdir(self.path)\n",
        "      # pull the git repo\n",
        "      cmdline('git clone https://github.com/'+self.rep[0]+'/'+self.rep[1]+'.git',True)\n",
        "      # Set the return value for rep rootpath\n",
        "      self.PATH=self.path+self.rep[1]\n",
        "    # show imported files\n",
        "    os.system('ls ' + root)  \n",
        "    #--repository required dependancies setup\n",
        "  def custom_reps_setup(self):\n",
        "    # cyclegan\n",
        "    if 'pytorch-CycleGAN-and-pix2pix' in self.repos:\n",
        "      !export PYTHONPATH={root}/pytorch-CycleGAN-and-pix2pix:$PYTHONPATH\n",
        "      !pip install dominate\n",
        "    # custom stuff for CartoonGAN-tensorflow and keras-team/keras-contrib   \n",
        "    if 'keras-team/keras-contrib' in self.repos:\n",
        "      os.chdir(self.path+'/keras-contrib')\n",
        "      cmdline('python convert_to_tf_keras.py')\n",
        "      cmdline('USE_TF_KERAS=1')\n",
        "      cmdline('python setup.py install')\n",
        "      import tensorflow as tf\n",
        "      tf.__version__     \n",
        "    # custom setup stuff for gallery-dl repo   \n",
        "    if 'mikf/gallery-dl' in self.repos:\n",
        "      os.chdir(root+'/gallery-dl')\n",
        "      cmdline(\"pip install -e . |grep 'succes'\",True)\n",
        "    # custom setup stuff for youtube-dl repo    \n",
        "    if 'ytdl-org/youtube-dl' in self.repos:\n",
        "      os.chdir(root+'/youtube-dl') \n",
        "      cmdline(\"pip install -e . |grep 'succes'\",True)      \n",
        "    # switch backt to root\n",
        "    os.chdir(self.path)    \n",
        "#--grab the username if a repos is installed\n",
        "#--generate a file of all other reps of users\n",
        "  def get_other_reps(self):          \n",
        "    for r in self.repos:\n",
        "      self.GUSER=r.split('/')[0]\n",
        "      self.repo_name=r.split('/')[1]\n",
        "      self.GitUsers.append(self.GUSER)      \n",
        "      !curl https://api.github.com/users/{self.GUSER}/repos?per_page=100 \\\n",
        "            | grep -o 'git@[^\"]*' > {root}/info.txt\n",
        "      cmdline('cat '+root+\"/info.txt |awk -F ':' '{print $2}'|awk -F '.' '{print $1}' \\\n",
        "          > \"+self.path+\"/\"+self.GUSER+\"_repositories.txt\",True)      \n",
        "      with open(root+'/info.txt','r') as f:\n",
        "        for line in f:\n",
        "          cline=line.split(':')[1].split('.')[0]\n",
        "          self.sub_repo_list.append(cline),  \n",
        "            #--return path and sub reps\n",
        "  def __repr__(self):\n",
        "    return self.path,self.sub_repo_list\n",
        "# Hauling Ass!\n",
        "G,R=GitGo(reps,sub_repos=True,path=root)\n",
        "loot = recursive_glob(root,'req*.txt')\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2fwdt26oPJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keyword='turtle'\n",
        "logdir=root+'/LOG'\n",
        "datadir=root+'/DATA'\n",
        "checkpointdir='/CHECKPOINT'\n",
        "!mkdir     {checkpointdir}\n",
        "!mkdir     {datadir}\n",
        "!mkdir     {logdir}\n",
        "# Scrape the crap!\n",
        "!gallery-dl -d /content/image_learning/DATA \\\n",
        "    --range 1-25 https://flickr.com/search/?text={keyword}\n",
        "# Initialization tensorboard\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# Add to tf.keras callback\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "!bash {root}/piss-ant-pix2pix/image_folder_make_set_train.sh \\\n",
        "      {root}/DATA/flickr/search/turtle 10 prep\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PB9x9ME4zEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# /content/image_learning/DATA/flickr/search/turtle\n",
        "!cat /content/image_learning/piss-ant-pix2pix/image_folder_make_set_train.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1stJ8G3b6-dG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(root+'/'+piss-ant-pix2pix)\n",
        "\n",
        "if train:\n",
        "  cmdline('python pix2pix.py \\\n",
        "      --mode train \\\n",
        "      --output_dir '+input_img_folder+'_train \\\n",
        "      --max_epochs '+training_epochs+' \\\n",
        "      --input_dir '+input_img_folder+'_resize/_combined/train \\\n",
        "      --which_direction BtoA &')\n",
        "\n",
        "if test:\n",
        "  cmdline('python pix2pix.py \\\n",
        "      --mode test \\\n",
        "      --output_dir '+input_img_folder+'_test \\\n",
        "      --input_dir '+input_img_folder+'_resize/_combined/val \\\n",
        "      --checkpoint '+input_img_folder+'_train &')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzQ2f2GKKHVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu0Qfjo-j1YZ",
        "colab_type": "text"
      },
      "source": [
        "# Experimenteel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D_VhmNCpfdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# GitGo(['tensorflow/tensorboard-plugin-example'],sub_repos=True,path=root)\n",
        "! python /content/image_learning/tensorboard-plugin-example/greeter_tensorboard/main.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_ot5P4wqNNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/image_learning/Keras-GAN\n",
        "!pip install -r requirements.txt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z5utjkdi0TH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python /content/image_learning/examples/tensorflow_examples/models/pix2pix/data_download.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj_zlxPTiz47",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie41_kt9rrJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# os.chdir('discogan/images')\n",
        "\n",
        "!wget 'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/cityscapes.tar.gz' -O /content/image_learning/Keras-GAN/discogan/images/cityscapes.tar.gz\n",
        "\n",
        "!tar -zxvf cityscapes.tar.gz\n",
        "\n",
        "!ls -la\n",
        "os.chdir(`root)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5mjcqoRvOQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G_N='discogan'\n",
        "# os.chdir(G_N+'/images/')\n",
        "\n",
        "!wget 'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/cityscapes.tar.gz' -s -O /content/image_learning/Keras-GAN/discogan/images/cityscapes.tar.gz\n",
        "!tar -zxf cityscapes.tar.gz\n",
        "os.chdir('../')\n",
        "loot = recursive_glob(root,'downl*.sh')\n",
        "for l in loot:\n",
        "  x=l.split('.')[0]\n",
        "  print(x)\n",
        "  os.chdir(x)\n",
        "  !ls -l\n",
        "  print(x.rstrip())\n",
        "\n",
        "#   !bash {l} facades maps ae_photos\n",
        "\n",
        "# os.chdir(root+'/Keras-GAN')\n",
        "# print(loot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRGkNt9Y0Psv",
        "colab_type": "text"
      },
      "source": [
        "apple2orange, summer2winter_yosemite, horse2zebra, monet2photo, cezanne2photo, ukiyoe2photo, vangogh2photo, maps, cityscapes, facades, iphone2dslr_flower, ae_photos\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XPVvaTTbmf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/image_learning/datasets/tensorflow_datasets/video\n",
        "# Start TensorBoard within the notebook using magics function\n",
        "%tensorboard — logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUPUMgQpi0ol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbda6101-2b24-42c2-fdc7-4cfa3872fcf0"
      },
      "source": [
        "%tensorboard — logdir logs"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqQ0_m1hcaKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "# tfds works in both Eager and Graph modes\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "# See available datasets\n",
        "print(tfds.list_builders())\n",
        "print(dir(tfds))\n",
        "# Construct a tf.data.Dataset\n",
        "ds_train, ds_test = tfds.load(name=\"oxford_flowers102\", split=[\"train\", \"test\"])\n",
        "\n",
        "# Build your input pipeline\n",
        "ds_train = ds_train.shuffle(1000).batch(128).prefetch(10)\n",
        "for features in ds_train.take(1):\n",
        "  image, label = features[\"image\"], features[\"label\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj-sUUihz2AH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x= '/content/image_learning/CycleGAN/pretrained_models/download_model.sh'\n",
        "# print(l.split('.')[0]) \n",
        "!cat /content/image_learning/examples/tensorflow_examples/models/nmt_with_attention/distributed_train.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y__zg0EIld-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /content/image_learning/examples/tensorflow_examples/models/nmt_with_attention/nmt.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV6irDiymBkF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxdRW0pZmAUy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOedifV-judM",
        "colab_type": "text"
      },
      "source": [
        "# DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhsb9ZgnjnXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile /content/image_learning/examples/tensorflow_examples/models/dcgan/dcgan_custom.py\n",
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Train.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from absl import app\n",
        "import tensorflow as tf # TF2\n",
        "from tensorflow_examples.models.nmt_with_attention import nmt\n",
        "from tensorflow_examples.models.nmt_with_attention import utils\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "\n",
        "class Train(object):\n",
        "  \"\"\"Train class.\n",
        "\n",
        "  Attributes:\n",
        "    epochs: Number of epochs.\n",
        "    enable_function: Decorate function with tf.function.\n",
        "    encoder: Encoder.\n",
        "    decoder: Decoder.\n",
        "    inp_lang: Input language tokenizer.\n",
        "    targ_lang: Target language tokenizer.\n",
        "    batch_size: Batch size.\n",
        "    per_replica_batch_size: Batch size per replica for sync replicas. Same as\n",
        "      batch_size for non distributed training.\n",
        "    optimizer: Optimizer.\n",
        "    loss_object: Object of the loss class.\n",
        "    train_loss_metric: Mean metric to keep track of the train loss value.\n",
        "    test_loss_metric: Mean metric to keep track of the test loss value.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, epochs, enable_function, encoder, decoder, inp_lang,\n",
        "               targ_lang, batch_size, per_replica_batch_size):\n",
        "    self.epochs = epochs\n",
        "    self.enable_function = enable_function\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.inp_lang = inp_lang\n",
        "    self.targ_lang = targ_lang\n",
        "    self.batch_size = batch_size\n",
        "    self.per_replica_batch_size = per_replica_batch_size\n",
        "    self.optimizer = tf.keras.optimizers.Adam()\n",
        "    self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "    self.train_loss_metric = tf.keras.metrics.Mean(name='train_loss')\n",
        "    self.test_loss_metric = tf.keras.metrics.Mean(name='test_loss')\n",
        "\n",
        "  def loss_function(self, real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = self.loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_) * 1. / self.batch_size\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    \"\"\"One train step.\n",
        "\n",
        "    Args:\n",
        "      inputs: tuple of input tensor, target tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    loss = 0\n",
        "    enc_hidden = self.encoder.initialize_hidden_state()\n",
        "\n",
        "    inp, targ = inputs\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
        "      dec_hidden = enc_hidden\n",
        "      dec_input = tf.expand_dims(\n",
        "          [self.targ_lang.word_index['<start>']] * self.per_replica_batch_size,\n",
        "          1)\n",
        "\n",
        "      for t in range(1, targ.shape[1]):\n",
        "        # passing enc_output to the decoder\n",
        "        predictions, dec_hidden, _ = self.decoder(\n",
        "            dec_input, dec_hidden, enc_output)\n",
        "        loss += self.loss_function(targ[:, t], predictions)\n",
        "        # using teacher forcing\n",
        "        dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = (self.encoder.trainable_variables +\n",
        "                 self.decoder.trainable_variables)\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    self.train_loss_metric(batch_loss)\n",
        "\n",
        "  def test_step(self, inputs_test):\n",
        "    \"\"\"One test step.\n",
        "\n",
        "    Args:\n",
        "      inputs_test: tuple of input tensor, target tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    loss = 0\n",
        "    enc_hidden = self.encoder.initialize_hidden_state()\n",
        "\n",
        "    inp_test, targ_test = inputs_test\n",
        "\n",
        "    enc_output, enc_hidden = self.encoder(inp_test, enc_hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims(\n",
        "        [self.targ_lang.word_index['<start>']] * self.per_replica_batch_size,\n",
        "        1)\n",
        "\n",
        "    for t in range(1, targ_test.shape[1]):\n",
        "      predictions, dec_hidden, _ = self.decoder(\n",
        "          dec_input, dec_hidden, enc_output)\n",
        "      loss += self.loss_function(targ_test[:, t], predictions)\n",
        "\n",
        "      prediction_id = tf.argmax(predictions, axis=1)\n",
        "      # passing the predictions back to the model as the input.\n",
        "      dec_input = tf.expand_dims(prediction_id, 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ_test.shape[1]))\n",
        "\n",
        "    self.test_loss_metric(batch_loss)\n",
        "\n",
        "  def training_loop(self, train_ds, test_ds):\n",
        "    \"\"\"Custom training and testing loop.\n",
        "\n",
        "    Args:\n",
        "      train_ds: Training dataset\n",
        "      test_ds: Testing dataset\n",
        "\n",
        "    Returns:\n",
        "      train_loss, test_loss\n",
        "    \"\"\"\n",
        "\n",
        "    if self.enable_function:\n",
        "      self.train_step = tf.function(self.train_step)\n",
        "      self.test_step = tf.function(self.test_step)\n",
        "\n",
        "    template = 'Epoch: {}, Train Loss: {}, Test Loss: {}'\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "      self.train_loss_metric.reset_states()\n",
        "      self.test_loss_metric.reset_states()\n",
        "\n",
        "      for inp, targ in train_ds:\n",
        "        self.train_step((inp, targ))\n",
        "\n",
        "      for inp_test, targ_test in test_ds:\n",
        "        self.test_step((inp_test, targ_test))\n",
        "\n",
        "      print (template.format(epoch,\n",
        "                             self.train_loss_metric.result().numpy(),\n",
        "                             self.test_loss_metric.result().numpy()))\n",
        "\n",
        "    return (self.train_loss_metric.result().numpy(),\n",
        "            self.test_loss_metric.result().numpy())\n",
        "\n",
        "\n",
        "def run_main(argv):\n",
        "  del argv\n",
        "  kwargs = utils.flags_dict()\n",
        "  main(**kwargs)\n",
        "\n",
        "\n",
        "def main(epochs, enable_function, buffer_size, batch_size, download_path,\n",
        "         num_examples=70000, embedding_dim=256, enc_units=1024, dec_units=1024):\n",
        "  file_path = utils.download(download_path)\n",
        "  train_ds, test_ds, inp_lang, targ_lang = utils.create_dataset(\n",
        "      file_path, num_examples, buffer_size, batch_size)\n",
        "  vocab_inp_size = len(inp_lang.word_index) + 1\n",
        "  vocab_tar_size = len(targ_lang.word_index) + 1\n",
        "\n",
        "  encoder = nmt.Encoder(vocab_inp_size, embedding_dim, enc_units, batch_size)\n",
        "  decoder = nmt.Decoder(vocab_tar_size, embedding_dim, dec_units)\n",
        "\n",
        "  train_obj = Train(epochs, enable_function, encoder, decoder,\n",
        "                    inp_lang, targ_lang, batch_size, batch_size)\n",
        "  print ('Training ...')\n",
        "  return train_obj.training_loop(train_ds, test_ds)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  utils.nmt_flags()\n",
        "  app.run(run_main)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}